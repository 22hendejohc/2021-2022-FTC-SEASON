package org.firstinspires.ftc.teamcode;

import android.graphics.Bitmap;

import com.qualcomm.robotcore.eventloop.opmode.Disabled;
import com.qualcomm.robotcore.eventloop.opmode.LinearOpMode;
import com.qualcomm.robotcore.eventloop.opmode.TeleOp;
import com.qualcomm.robotcore.util.RobotLog;
import com.qualcomm.robotcore.util.ThreadPool;
import com.vuforia.Frame;

import org.firstinspires.ftc.robotcore.external.ClassFactory;
import org.firstinspires.ftc.robotcore.external.function.Consumer;
import org.firstinspires.ftc.robotcore.external.function.Continuation;
import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import org.firstinspires.ftc.robotcore.external.matrices.MatrixF;
import org.firstinspires.ftc.robotcore.external.matrices.OpenGLMatrix;
import org.firstinspires.ftc.robotcore.external.navigation.AngleUnit;
import org.firstinspires.ftc.robotcore.external.navigation.AxesOrder;
import org.firstinspires.ftc.robotcore.external.navigation.AxesReference;
import org.firstinspires.ftc.robotcore.external.navigation.Orientation;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaLocalizer;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaTrackable;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaTrackableDefaultListener;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaTrackables;
import org.firstinspires.ftc.robotcore.internal.system.AppUtil;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Locale;



@TeleOp(name="Concept: Vuforia Nav Webcam", group ="Concept")
public class TESTING extends LinearOpMode {

    public static final String TAG = "Vuforia Navigation Sample";

    OpenGLMatrix lastLocation = null;


    int captureCounter = 0;
    File captureDirectory = AppUtil.ROBOT_DATA_DIR;


    VuforiaLocalizer vuforia;


    WebcamName camera;

    @Override public void runOpMode() {


        camera = hardwareMap.get(WebcamName.class, "camera");


        int cameraMonitorViewId = hardwareMap.appContext.getResources().getIdentifier("cameraMonitorViewId", "id", hardwareMap.appContext.getPackageName());
        VuforiaLocalizer.Parameters parameters = new VuforiaLocalizer.Parameters(cameraMonitorViewId);


        parameters.vuforiaLicenseKey = "AdVdFHb/////AAABmTrtSk2IBEC3kcsmf+jj6dZ+IBrlySlXBxLBhVux/9ynN40mNtmmJDumGH5KSUa/5I071PAVDJDhAiPVL6Gql0qF/uZa3YfPawIo15gbxdZ2J9OXEyLMEcMC2k/YRxocV44f8m9C4nX+5FElzBQc42BvMaMyr2TeTj+hzMEghGi4HjMr4E6Fqs6/sHoHbKpcESuS3OttD0mjfS+7tuoEhxMTAwFW8IfAmNTf5kKErxOdVMQbLHqOsWHDn8jv/UY5KMGKiHbqpl45TQX3tYzHn4VpCU9dcJbYNJneOcB4TNt2/ZyY+qNkLqisPNM7WtlL9m37Hh9932STvDtVRNMCQdDEU0iuwFZc7UCDy+6sjxrO";


        parameters.cameraName = camera;


        vuforia = ClassFactory.getInstance().createVuforia(parameters);


        vuforia.enableConvertFrameToBitmap();


        AppUtil.getInstance().ensureDirectoryExists(captureDirectory);



        VuforiaTrackables pictures = vuforia.loadTrackablesFromAsset("UltimateGoal");
        VuforiaTrackable image4 = pictures.get(0);
        image4.setName("Image 4");  //4

        VuforiaTrackable image5  = pictures.get(1);
        image5.setName("Image 5");  // 5

        VuforiaTrackable image3  = pictures.get(2);
        image3.setName("Image 3");  // 5

        VuforiaTrackable image2  = pictures.get(3);
        image2.setName("Image 2");  // 5

        VuforiaTrackable image1  = pictures.get(4);
        image1.setName("Image 1");  // 5


        List<VuforiaTrackable> allTrackables = new ArrayList<VuforiaTrackable>();
        allTrackables.addAll(pictures);


        float mmPerInch        = 25.4f;
        float mmBotWidth       = 18 * mmPerInch;            // ... or whatever is right for your robot
        float mmFTCFieldWidth  = (12*12 - 2) * mmPerInch;   // the FTC field is ~11'10" center-to-center of the glass panels


        OpenGLMatrix image4LocationOnField = OpenGLMatrix
                /* Then we translate the target off to the RED WALL. Our translation here
                is a negative translation in X.*/
                .translation(-mmFTCFieldWidth/2, 0, 0)
                .multiplied(Orientation.getRotationMatrix(
                        /* First, in the fixed (field) coordinate system, we rotate 90deg in X, then 90 in Z */
                        AxesReference.EXTRINSIC, AxesOrder.XZX,
                        AngleUnit.DEGREES, 90, 90, 0));
        image4.setLocationFtcFieldFromTarget(image4LocationOnField);
        RobotLog.ii(TAG, "Image 4=%s", format(image4LocationOnField));

       /*
        * To place the Stones Target on the Blue Audience wall:
        * - First we rotate it 90 around the field's X axis to flip it upright
        * - Finally, we translate it along the Y axis towards the blue audience wall.
        */
        OpenGLMatrix image5LocationOnField = OpenGLMatrix
                /* Then we translate the target off to the RED WALL. Our translation here
                is a negative translation in X.*/
                .translation(-mmFTCFieldWidth/2, 0, 0)
                .multiplied(Orientation.getRotationMatrix(
                        /* First, in the fixed (field) coordinate system, we rotate 90deg in X, then 90 in Z */
                        AxesReference.EXTRINSIC, AxesOrder.XZX,
                        AngleUnit.DEGREES, 90, 90, 0));
        image5.setLocationFtcFieldFromTarget(image5LocationOnField);
        RobotLog.ii(TAG, "Image 5=%s", format(image5LocationOnField));

        OpenGLMatrix image3LocationOnField = OpenGLMatrix
                /* Then we translate the target off to the RED WALL. Our translation here
                is a negative translation in X.*/
                .translation(-mmFTCFieldWidth/2, 0, 0)
                .multiplied(Orientation.getRotationMatrix(
                        /* First, in the fixed (field) coordinate system, we rotate 90deg in X, then 90 in Z */
                        AxesReference.EXTRINSIC, AxesOrder.XZX,
                        AngleUnit.DEGREES, 90, 90, 0));
        image3.setLocationFtcFieldFromTarget(image3LocationOnField);
        RobotLog.ii(TAG, "Image 3=%s", format(image3LocationOnField));

        OpenGLMatrix image2LocationOnField = OpenGLMatrix
                /* Then we translate the target off to the RED WALL. Our translation here
                is a negative translation in X.*/
                .translation(-mmFTCFieldWidth/2, 0, 0)
                .multiplied(Orientation.getRotationMatrix(
                        /* First, in the fixed (field) coordinate system, we rotate 90deg in X, then 90 in Z */
                        AxesReference.EXTRINSIC, AxesOrder.XZX,
                        AngleUnit.DEGREES, 90, 90, 0));
        image2.setLocationFtcFieldFromTarget(image2LocationOnField);
        RobotLog.ii(TAG, "Image 2=%s", format(image2LocationOnField));

        OpenGLMatrix image1LocationOnField = OpenGLMatrix
                /* Then we translate the target off to the RED WALL. Our translation here
                is a negative translation in X.*/
                .translation(-mmFTCFieldWidth/2, 0, 0)
                .multiplied(Orientation.getRotationMatrix(
                        /* First, in the fixed (field) coordinate system, we rotate 90deg in X, then 90 in Z */
                        AxesReference.EXTRINSIC, AxesOrder.XZX,
                        AngleUnit.DEGREES, 90, 90, 0));
        image1.setLocationFtcFieldFromTarget(image1LocationOnField);
        RobotLog.ii(TAG, "Image 1=%s", format(image1LocationOnField));

        OpenGLMatrix robotFromCamera = OpenGLMatrix
                .translation(mmBotWidth/2,0,0)
                .multiplied(Orientation.getRotationMatrix(
                        AxesReference.EXTRINSIC, AxesOrder.XZY,
                        AngleUnit.DEGREES, 90, 90, 0));
        RobotLog.ii(TAG, "camera=%s", format(robotFromCamera));

        ((VuforiaTrackableDefaultListener)image4.getListener()).setCameraLocationOnRobot(parameters.cameraName, robotFromCamera);
        ((VuforiaTrackableDefaultListener)image5.getListener()).setCameraLocationOnRobot(parameters.cameraName, robotFromCamera);
        ((VuforiaTrackableDefaultListener)image3.getListener()).setCameraLocationOnRobot(parameters.cameraName, robotFromCamera);
        ((VuforiaTrackableDefaultListener)image2.getListener()).setCameraLocationOnRobot(parameters.cameraName, robotFromCamera);
        ((VuforiaTrackableDefaultListener)image1.getListener()).setCameraLocationOnRobot(parameters.cameraName, robotFromCamera);


        telemetry.addData(">", "Press Play to start tracking");
        telemetry.update();
        waitForStart();

        pictures.activate();

        boolean buttonPressed = false;
        while (opModeIsActive()) {

            if (gamepad1.a && !buttonPressed) {
                captureFrameToFile();
                }
            buttonPressed = gamepad1.a;

            for (VuforiaTrackable trackable : allTrackables) {

                telemetry.addData(trackable.getName(), ((VuforiaTrackableDefaultListener)trackable.getListener()).isVisible() ? "Visible" : "Not Visible");    //

                OpenGLMatrix robotLocationTransform = ((VuforiaTrackableDefaultListener)trackable.getListener()).getUpdatedRobotLocation();
                if (robotLocationTransform != null) {
                    lastLocation = robotLocationTransform;
                }
            }

            if (lastLocation != null) {
                //  RobotLog.vv(TAG, "robot=%s", format(lastLocation));
                telemetry.addData("Pos", format(lastLocation));
            } else {
                telemetry.addData("Pos", "Unknown");
            }
            telemetry.update();
        }
    }


    String format(OpenGLMatrix transformationMatrix) {
        return transformationMatrix.formatAsTransform();
    }

    
    void captureFrameToFile() {
        vuforia.getFrameOnce(Continuation.create(ThreadPool.getDefault(), new Consumer<Frame>()
            {
            @Override public void accept(Frame frame)
                {
                Bitmap bitmap = vuforia.convertFrameToBitmap(frame);
                if (bitmap != null) {
                    File file = new File(captureDirectory, String.format(Locale.getDefault(), "VuforiaFrame-%d.png", captureCounter++));
                    try {
                        FileOutputStream outputStream = new FileOutputStream(file);
                        try {
                            bitmap.compress(Bitmap.CompressFormat.PNG, 100, outputStream);
                        } finally {
                            outputStream.close();
                            telemetry.log().add("captured %s", file.getName());
                        }
                    } catch (IOException e) {
                        RobotLog.ee(TAG, e, "exception in captureFrameToFile()");
                    }
                }
            }
        }));
    }
}
